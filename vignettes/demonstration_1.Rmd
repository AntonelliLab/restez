---
title: "Demo 1: Search and Fetch"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Demonstration 1: search and fetch}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this demonstration we are going to search NCBI with a custom search term, download accession IDs, and retrieve fasta sequences using
restez.

## Setup

First, we need to download and setup the restez database. When we use `gb_download()` we are going to select 'rodents'. We are downloading
rodents because they are the smallest available set of sequences, minismising the download time for this demonstration.

```{r setup-database, eval=FALSE, include=TRUE}
library(restez)
fp <- file.path(getwd(), 'demo')
dir.create(fp)
restez_path_set(fp)
gb_download()
db_create()
```

## Search NCBI

After setting up the database, we can then identify the sequences we are interested in. For this, we cannot use restez to perform a search,
because the download just doesn't contain enough metadata for the full range of possible search arguments.

Let's pretend we're intersted in COI sequences for a group of Rodents called the Sciuromorpha. We can create an NCBI search term,
use `entrez_search` to perform the search and then retrieve the accession IDs using `entrez_fetch` and the `acc` rettype. `entrez_fetch`
returns a single text that will need to be split up by the newline character. Finally, we should drop any version number after the downloaded
accessions. This is not strictly necessary, but it makes it easier to check our results from restez later.


```{r search, eval=FALSE, include=TRUE}
# 33553 - Sciuromorpha - squirrel-like things
search_term <- 'txid33553[Organism:exp] AND COI [GENE]'
search_object <- rentrez::entrez_search(db = 'nucleotide', term = search_term,
                                        use_history = TRUE, retmax = 0)
accessions <- rentrez::entrez_fetch(db = 'nucleotide',
                                    web_history = search_object$web_history,
                                    rettype = 'acc')
accessions <- strsplit(x = accessions, split = '\\n')[[1]]
accessions <- sub(pattern = '\\.[0-9]+', replacement = '', x = accessions)
```


## Retrieve sequences

To fetch the sequences from the database we set up, we can just use the `gb_fasta_get` function. This is a lot faster than using the Entrez API
for very large requests, because NCBI limits the number of requests per user, often to as lower as 300 items per request with varying time
delays.

```{r retrieve, eval=FALSE, include=TRUE}
coi_sequences <- gb_fasta_get(id = accessions)
# are all accessions in results?
all(accessions %in% names(coi_sequences))
# .... no
```

When exploring the above results however we notice that not all the accession IDs that were provided are in the returned `coi_sequences`.
This is because restez only downloads GenBank sequences, and these 'missing' sequence IDs are RefSeq sequences. Luckily, it seems all
RefSeq sequences are also deposited in GenBank under a different ID, so no sequence information is missing from our results.
We can look up the alternative ID and test whether it is in our `accesssions` vector.

```{r parse, eval=FALSE, include=TRUE}
# are all accessions in results?
all(accessions %in% names(coi_sequences))
# .... no
accessions[!accessions %in% names(coi_sequences)]
# NC* refers to RefSeq sequences and are not currently available through restez
# The sequence however exists in GB under a different id which we can find like so
smmry <- rentrez::entrez_summary(db = 'nucleotide', id = 'NC_027278')
# This ID does exist in our results.
smmry$assemblyacc %in% accessions
```

## Take down

Finally, because this is only a demonstration. It might be a good idea to delete the database we built to free up hard disk space.

```{r delete, eval=FALSE, include=TRUE}
db_delete()
```
